{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FÃºtbol Match Highlights<br>\n",
    "Source Face Embedding - Capstone 2<br>\n",
    "Tom Widdows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Housekeeping..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../code')\n",
    "import settings as s\n",
    "\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from support_class import Fball, FaceAligner, time_it\n",
    "\n",
    "start_all = time.time()  # track time for notebook to run\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common variables and settings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common variables used throughout the notebook\n",
    "random.seed(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = [f_name for d_name in Path(s.SOURCE_DIR_jn).glob(\"*\") for f_name in d_name.glob('*') if d_name.is_dir() if f_name.is_file() if f_name.suffix=='.jpg']\n",
    "file_names = [Path(f).name for f in path_file]\n",
    "dir_names = [Path(f).parent for f in path_file]\n",
    "df_s = pd.DataFrame(zip(file_names, dir_names, path_file), columns=['file','path','path_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model to check for Blury Faces..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_vs_unfocused_model = Fball.load_model('focused_vs_unfocused_model')\n",
    "focused_vs_unfocused_scaler = Fball.load_model('focused_vs_unfocused_scaler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model to check real faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_vs_object_model = Fball.load_model('face_vs_object_model')\n",
    "face_vs_object_scaler = Fball.load_model('face_vs_object_scaler') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the recognizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = Fball.load_model('recognizer')\n",
    "le = Fball.load_model('le') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# utility function for mtcnn detecting faces\n",
    "\n",
    "def find_mtcnn_faces():\n",
    "    fa = FaceAligner(desiredFaceWidth=256)\n",
    "    detector = MTCNN()  # we are finding this on the scaled image and storing points based on the scaled image\n",
    "\n",
    "    files=[]\n",
    "    processed_files = df_s['path_file']\n",
    "    for file in processed_files:\n",
    "        pickle_dir = file.parent / 'mtcnn_faces' / 'mtcnn_pickles' \n",
    "        if len(list(pickle_dir.glob(file.stem + '*' + '.pkl'))) == 0:  # get only the files that have not been processed\n",
    "            files.append(file)\n",
    "            \n",
    "    for file in files:  # premake all directories\n",
    "        Path(file.parent / 'images_with_no_faces').mkdir(parents=True, exist_ok=True)\n",
    "        Path(file.parent / 'mtcnn_faces' / 'mtcnn_pickles').mkdir(parents=True, exist_ok=True)\n",
    "        Path(file.parent / 'mtcnn_faces' / 'mtcnn_blury').mkdir(parents=True, exist_ok=True)\n",
    "        Path(file.parent / 'mtcnn_faces' / 'mtcnn_not_face').mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "    for c, file in enumerate(files):  # reads an image (photograph) with multiple faces\n",
    "        print(str(c+1) + ' of ' + str(len(files)) + '  '+ file.name + '                    ', end='\\r')\n",
    "        image = cv2.imread(str(file))\n",
    "        result = detector.detect_faces(image)\n",
    "        \n",
    "        result_count = len(result)\n",
    "        if result_count == 0: # no faces found in entire image, move image and gt pickle, move to next image\n",
    "            f = file.parent / 'images_with_no_faces' / file.name\n",
    "            shutil.move(file, f)\n",
    "            shutil.move(file.with_suffix('.pkl'), f.with_suffix('.pkl'))\n",
    "            continue # move to next image\n",
    "            \n",
    "        for i, face in enumerate(result):\n",
    "            (x, y, w, h) = face['box']\n",
    "            rect = [x,y,w,h]\n",
    "            face_aligned = fa.align(image, rect, face['keypoints']['left_eye'], face['keypoints']['right_eye'])\n",
    "            face_file = file.parent / 'mtcnn_faces' / (file.stem + '_faceno_' + str(i).zfill(4)+'.jpg')\n",
    "            \n",
    "            gray_face_aligned = cv2.cvtColor(face_aligned, cv2.COLOR_BGR2GRAY)\n",
    "            X = cv2.resize(gray_face_aligned, (64,64)).flatten()\n",
    "            X = face_vs_object_scaler.transform([X])\n",
    "            pred = face_vs_object_model.predict_proba(X)[0]\n",
    "            if pred[0] > .20:  # [0] is no face percent, [1] is face percent, .20 is model cutoff\n",
    "                f = file.parent / 'mtcnn_faces' / 'mtcnn_not_face' / face_file.name\n",
    "                cv2.imwrite(str(f), face_aligned)\n",
    "                result_count = result_count - 1\n",
    "                if result_count == 0: # no faces found in entire image, move image and gt pickle, move to next image\n",
    "                    f = file.parent / 'images_with_no_faces' / file.name\n",
    "                    shutil.move(file, f)\n",
    "                    shutil.move(file.with_suffix('.pkl'), f.with_suffix('.pkl'))\n",
    "                continue\n",
    "                \n",
    "            X = Fball.get_sharp_data(gray_face_aligned)\n",
    "            X = focused_vs_unfocused_scaler.transform([X])\n",
    "            pred = focused_vs_unfocused_model.predict_proba(X)[0]\n",
    "            if pred[0] > .80:  # if blur % is > 22, consider the photo blurry (same as preds[1] <= 78)\n",
    "                f = file.parent / 'mtcnn_faces' / 'mtcnn_blury' / face_file.name\n",
    "                cv2.imwrite(str(f), face_aligned)\n",
    "                result_count = result_count - 1\n",
    "                if result_count == 0: # no faces found in entire image, move image and gt pickle, move to next image\n",
    "                    f = file.parent / 'images_with_no_faces' / file.name\n",
    "                    shutil.move(file, f)\n",
    "                    shutil.move(file.with_suffix('.pkl'), f.with_suffix('.pkl'))\n",
    "                continue\n",
    "           \n",
    "            confidence = face['confidence']\n",
    "            org_image_left_eye = face['keypoints']['left_eye']\n",
    "            org_image_right_eye = face['keypoints']['right_eye']\n",
    "            org_image_nose = face['keypoints']['nose']\n",
    "            org_image_mouth_left = face['keypoints']['mouth_left']\n",
    "            org_image_mouth_right = face['keypoints']['mouth_right']\n",
    "            face_image_left_eye = tuple(np.subtract(org_image_left_eye, (x, y)))\n",
    "            face_image_right_eye = tuple(np.subtract(org_image_right_eye, (x, y)))\n",
    "            face_image_nose = tuple(np.subtract(org_image_nose, (x, y)))\n",
    "            face_image_mouth_left = tuple(np.subtract(org_image_mouth_left, (x, y)))\n",
    "            face_image_mouth_right = tuple(np.subtract(org_image_mouth_right, (x, y)))\n",
    "            face_pickle = file.parent / 'mtcnn_faces' /'mtcnn_pickles'/ (file.stem + '_faceno_' + str(i).zfill(4)+'.pkl')\n",
    "            vec = Fball.get_face_embedding(face_aligned)\n",
    "            skin_tone_pct = Fball.skin_tone(face_aligned)\n",
    "            cv2.imwrite(str(face_file), face_aligned)\n",
    "            dict = {'face_file':face_file, 'path_file':file, 'faceno':str(i).zfill(4), 'faceno_int':i, 'x1':x, 'y1':y, 'x2': x+w, 'y2':y+h, 'w':w, 'h':h, 'confidence':confidence, 'sq_pixels': w*h,  'org_image_h': image.shape[0], 'org_image_w':image.shape[1], 'org_image_sq_pixels':image.shape[0] * image.shape[1], 'face_pct': (w*h)/(image.shape[0] * image.shape[1]), 'org_image_left_eye':org_image_left_eye, 'org_image_right_eye':org_image_right_eye, 'org_image_nose':org_image_nose, 'org_image_mouth_left':org_image_mouth_left, 'org_image_mouth_right':org_image_mouth_right, 'face_image_left_eye':face_image_left_eye, 'face_image_right_eye':face_image_right_eye, 'face_image_nose':face_image_nose, 'face_image_mouth_left':face_image_mouth_left, 'face_image_mouth_right':face_image_mouth_right, 'skin_tone_pct':skin_tone_pct, 'vec':[vec]}\n",
    "            with open(face_pickle, 'wb') as handle:\n",
    "                pickle.dump(dict, handle)\n",
    "    return \n",
    "\n",
    "# face detection using MTCNN classifier\n",
    "find_mtcnn_faces()\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pickle_files = [f_name for d_name in Path(s.SOURCE_DIR_jn).glob(\"*\") for f_name in d_name.glob('mtcnn_faces/mtcnn_pickles/*') if d_name.is_dir() if f_name.is_file() if f_name.suffix=='.pkl']\n",
    "face_jpg_files = [(f_name.parent.parent / f_name.name).with_suffix('.jpg') for f_name in face_pickle_files]\n",
    "source_files = [(f_name.parent.parent / f_name.stem[0:-12]).with_suffix('.jpg') for f_name in face_jpg_files]\n",
    "df = pd.DataFrame(zip(face_pickle_files, face_jpg_files, source_files), columns=['file','path','path_file'])\n",
    "df.columns = ['face_pickle_files','face_jpg_files', 'source_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pkls = list(df['face_pickle_files'])\n",
    "face_jpgs = list(df['face_jpg_files'])\n",
    "source_files = list(df['source_files'])\n",
    "vecs = []\n",
    "vecs_jpgs = []\n",
    "for i, face_pkl in enumerate(face_pkls):\n",
    "    with open(face_pkl, 'rb') as handle:\n",
    "        d = pickle.load(handle)\n",
    "        if 'vec' in d:\n",
    "            v = d['vec'][0]\n",
    "            if v.size == 128:\n",
    "                vecs.append(d['vec'][0])\n",
    "                vecs_jpgs.append(face_jpgs[i])\n",
    "            else:\n",
    "                print(face_jpgs[i])\n",
    "                raise ValueError('The 128d face code (vec) is the incorrect size in the above file')\n",
    "        else:\n",
    "            print(face_jpgs[i])\n",
    "            raise ValueError('The 128d face code (vec) in not contained in the above file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def recognize_face(vecs):\n",
    "    preds = recognizer.predict_proba(vecs)\n",
    "    for i, pred in enumerate(preds):\n",
    "        j = np.argmax(pred)\n",
    "        proba = pred[j]\n",
    "        name = le.classes_[j]\n",
    "        if j == 1 and proba > .98:\n",
    "            s_proba = f'pct_{proba*100:.0f}_'.zfill(3)\n",
    "            target = (Path('../../data/03_found_targets') / Path(s_proba +  str(face_jpgs[i].name)))\n",
    "            shutil.copyfile(face_jpgs[i], target)\n",
    "            target = (Path('../../data/03_found_targets') / Path(s_proba +  str(source_files[i].name)))\n",
    "            shutil.copyfile(source_files[i], target)\n",
    "recognize_face(vecs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
