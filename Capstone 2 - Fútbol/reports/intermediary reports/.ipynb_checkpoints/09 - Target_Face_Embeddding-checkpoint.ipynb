{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fútbol Match Highlights<br>\n",
    "Extended Modeling - Capstone 2<br>\n",
    "Tom Widdows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Housekeeping..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../code')\n",
    "import settings as s\n",
    "\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import lightgbm  as  lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from matplotlib.colors import rgb_to_hsv\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter, PercentFormatter, StrMethodFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw \n",
    "import pprint\n",
    "import random\n",
    "from scipy.stats import t, norm, ttest_ind, ttest_rel, zscore\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score, classification_report\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    SCORERS,  # # sorted(SCORERS.keys())\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    plot_confusion_matrix,\n",
    "    roc_curve\n",
    ")\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, LassoCV\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, binarize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from utility import read_image\n",
    "import time\n",
    "\n",
    "start_all = time.time()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decorators..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decorator to help with timing functions\n",
    "def time_it(func):\n",
    "    \"\"\"Decorator function to time functions in Jupyter Notebook\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f'{time.strftime(\"%H:%M:%S\", time.gmtime(int(time.time() - start)))}')\n",
    "        return result\n",
    "    return wrapper    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility functions\n",
    "\n",
    "# save pickle\n",
    "def save_obj(obj, name):\n",
    "    import pickle\n",
    "    with open(DATA_DIR / '10_other/objects' / str(name + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# load pickle\n",
    "def load_obj(name ):\n",
    "    import pickle\n",
    "    with open(DATA_DIR / '10_other/objects' / str(name + '.pkl'), 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "\n",
    "# iqr to calculate max of boxplot\n",
    "def max_y_iqr(x):\n",
    "    q75, q25 = np.percentile(x, [75 ,25])\n",
    "    iqr = q75 - q25\n",
    "    y_max = np.percentile(x, [75]) + (iqr*2)\n",
    "    return(y_max)\n",
    "\n",
    "\n",
    "# print blank lines\n",
    "def bl(qty=1):\n",
    "    for l in range(qty):\n",
    "        print()\n",
    "    \n",
    "\n",
    "def merge_dicts(*dict_args):\n",
    "    \"\"\"\n",
    "    Given any number of dicts, shallow copy and merge into a new dict,\n",
    "    precedence goes to key value pairs in latter dicts.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for dictionary in dict_args:\n",
    "        result.update(dictionary)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return best thresholds\n",
    "def cutoff_youdens_j(fpr,tpr,thresholds):\n",
    "    j_scores = tpr-fpr\n",
    "    j_ordered = sorted(zip(j_scores,thresholds))\n",
    "    return j_ordered[-1][1]\n",
    "\n",
    "# get a list of all the faces and show a sample\n",
    "@time_it\n",
    "def show_faces(faces):\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "    faces = faces.values.tolist()\n",
    "    if len(faces) > 10:  # sample w/o replacement if we have enough, otherwise use replacement\n",
    "        faces = random.sample(faces, 10)  # sample w/o replacement\n",
    "    else:\n",
    "        faces = random.choices(faces, k=10)  # sample w/ replacement\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    for i, file in enumerate(faces):\n",
    "        img = plt.imread(str(file))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        plt.show()        \n",
    "        \n",
    "# get a list of all the faces and show a sample\n",
    "def show_non_faces(df):\n",
    "    faces = [p for p in df['no_face_file']]\n",
    "    if len(faces) > 64:  # sample w/o replacement if we have enough, otherwise use replacement\n",
    "        faces = random.sample(faces, 64)  # sample w/o replacement\n",
    "    else:\n",
    "        faces = random.choices(faces, k=64)  # sample w/ replacement\n",
    "\n",
    "    fig, axs = plt.subplots(8, 8, figsize=(12, 12))\n",
    "    axs = axs.flatten()\n",
    "    for i, file in enumerate(faces):\n",
    "        img = plt.imread(file)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].imshow(img)\n",
    "        \n",
    "        \n",
    "# plot histogram of predicted probability\n",
    "def pred_prob_hist(X_valid, bins=8, xlabel='positive', cutoff=0.5):\n",
    "    plt.hist(y_pred_prob, bins=bins)\n",
    "    plt.xlim(0,1)\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    ax.xaxis.set_major_formatter(PercentFormatter(1))\n",
    "    ax.axvline(x=cutoff, ymin=0, ymax=1, color='r', linewidth=3,  linestyle='--')\n",
    "    plt.title(\"Histogram of predicted probabilities\")\n",
    "    plt.xlabel(\"Predicted probability of \"+xlabel)\n",
    "    plt.ylabel('Frequency');\n",
    "    colors = ['darkred']\n",
    "    lines = [Line2D([0], [0], color=c, linewidth=3, linestyle='--') for c in colors]\n",
    "    labels = ['Cutoff']\n",
    "    plt.legend(lines, labels)\n",
    "    plt.show();\n",
    "    bl()\n",
    "\n",
    "    \n",
    "# plot feature importances\n",
    "def feat_imp_plot(df, model, n_features, max_features=30):\n",
    "    n_features = min(n_features, max_features)\n",
    "    d = dict(zip(df.columns, model.feature_importances_))\n",
    "    ss = sorted(d, key=d.get, reverse=True)\n",
    "    top_names = ss[0:n_features]\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(n_features), [d[i] for i in top_names], color=\"r\", align=\"center\")\n",
    "    plt.xlim(-1, n_features)\n",
    "    plt.xticks(range(n_features), top_names, rotation=\"vertical\")\n",
    "\n",
    "    \n",
    "# draw diag line\n",
    "def abline(slope, intercept):\n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '--')\n",
    "\n",
    "\n",
    "# plot roc curve\n",
    "def plot_roc_curve(y_valid, y_pred_prob):\n",
    "    fpr, tpr, thresholds = roc_curve(y_valid, y_pred_prob.ravel())\n",
    "    optimal_cutoff = cutoff_youdens_j(fpr,tpr,thresholds)\n",
    "    y_pred_class = binarize(y_pred_prob.reshape(1,-1), optimal_cutoff) \n",
    "    tn, fp, fn, tp = confusion_matrix(y_valid, y_pred_class.ravel()).ravel()\n",
    "    false_positive_rate = fp / (fp + tn)\n",
    "    true_positive_rate = tp / (tp + fn)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_formatter(PercentFormatter(1))\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "    plt.xticks(fontsize=12, rotation=0)\n",
    "    plt.yticks(fontsize=12, rotation=0)\n",
    "    plt.title('ROC curve\\n', fontsize=16)\n",
    "    plt.xlabel('False Positive Rate\\nFP / (FP + TN)', fontsize=14)  # : (1 - Specificity)\n",
    "    plt.ylabel('True Positive Rate (Recall)\\nTP / (TP + FN)', fontsize=14)  # : (Recall)\n",
    "    plt.grid(True)\n",
    "    abline(slope=1,intercept=0)\n",
    "    ax.axvline(x=false_positive_rate, ymin=0, ymax=true_positive_rate, color='r', linestyle='--')\n",
    "    ax.axhline(y=true_positive_rate, xmin=0, xmax=false_positive_rate, color='r', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('images/ROC_Curve')\n",
    "    return optimal_cutoff\n",
    "\n",
    "\n",
    "# plot confusion matrix plus\n",
    "def plot_cm_plus(tn, fp, fn, tp):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patheffects as path_effects\n",
    "    from matplotlib import transforms\n",
    "    import numpy as np\n",
    "\n",
    "    def range_brace(x_min, x_max, mid=0.75, \n",
    "                    beta1=50.0, beta2=100.0, height=1, \n",
    "                    initial_divisions=11, resolution_factor=1.5):\n",
    "        # determine x0 adaptively values using second derivitive\n",
    "        # could be replaced with less snazzy:\n",
    "        #   x0 = NP.arange(0, 0.5, .001)\n",
    "        x0 = np.array(())\n",
    "        tmpx = np.linspace(0, 0.5, initial_divisions)\n",
    "        tmp = beta1**2 * (np.exp(beta1*tmpx)) * (1-np.exp(beta1*tmpx)) / np.power((1+np.exp(beta1*tmpx)),3)\n",
    "        tmp += beta2**2 * (np.exp(beta2*(tmpx-0.5))) * (1-np.exp(beta2*(tmpx-0.5))) / np.power((1+np.exp(beta2*(tmpx-0.5))),3)\n",
    "        for i in range(0, len(tmpx)-1):\n",
    "            t = int(np.ceil(resolution_factor*max(np.abs(tmp[i:i+2]))/float(initial_divisions)))\n",
    "            x0 = np.append(x0, np.linspace(tmpx[i],tmpx[i+1],t))\n",
    "        x0 = np.sort(np.unique(x0)) # sort and remove dups\n",
    "        # half brace using sum of two logistic functions\n",
    "        y0 = mid*2*((1/(1.+np.exp(-1*beta1*x0)))-0.5)\n",
    "        y0 += (1-mid)*2*(1/(1.+np.exp(-1*beta2*(x0-0.5))))\n",
    "        # concat and scale x\n",
    "        x = np.concatenate((x0, 1-x0[::-1])) * float((x_max-x_min)) + x_min\n",
    "        y = np.concatenate((y0, y0[::-1])) * float(height)\n",
    "        return (x,y)\n",
    "\n",
    "    fig  = plt.figure(figsize=(18, 9))\n",
    "    grid_shape = (39,37)\n",
    "\n",
    "    axes_list = ['ax_n1', 'ax_n2', 'ax_predicted_negative', 'ax_predicted_positive', 'ax_actual_negative', 'ax_actual_positive', \n",
    "    'ax_true_negative', 'ax_false_positive',  'ax_false_negative', 'ax_true_positive', 'ax_total_predicted_negative', 'ax_total_predicted_positive',  'ax_total_actual_negative', 'ax_total_actual_positive', 'ax_precision', 'ax_negative_predictive_value',  'ax_accuracy', 'ax_f1', 'ax_specificity', 'ax_sensitivity',  'ax_predicted_class', 'ax_actual_class', 'ax_top_brace', 'ax_left_brace']\n",
    "    typex = ['coordinates', 'spans', 'facecolor', 'spines']\n",
    "    coordinates = [[(6,3),(2,4), 'w', False], [(24,23),(4,5), 'lavender', True], [(6,7),(2,8), 'pink', True], [(6,15),(2,8), 'pink', True], [(8,3),(8,4), 'pink', True], [(16,3),(8,4), 'pink', True], [(8,7),(8,8), 'w', True], [(8,15),(8,8), 'w', True], [(16,7),(8,8), 'w', True], [(16,15),(8,8), 'w', True], [(24,7),(4,8), 'lavender', True], [(24,15),(4,8), 'lavender', True], [(8,23),(8,5), 'lavender', True], [(16,23),(8,5), 'lavender', True], [(30,15),(9,8), 'antiquewhite', True], [(30,7),(9,8), 'antiquewhite', True], [(30,25),(9,6), 'antiquewhite', True], [(30,31),(9,6), 'antiquewhite', True], [(8,29),(8,8), 'antiquewhite', True], [(16,29),(8,8), 'antiquewhite', True], [(0,7),(2,16), 'w', False], [(8,0),(16,1), 'w', False], [(2,7),(3,16), 'w', False], [(8,1),(16,1), 'w', False]   ]\n",
    "    d = {}\n",
    "    for ax, coordinates in zip(axes_list, coordinates):\n",
    "        d[ax] = dict(zip(typex, coordinates))\n",
    "    axes={}    \n",
    "    for ax, v in d.items():\n",
    "        loc = d[ax]['coordinates']\n",
    "        rowspan, colspan = d[ax]['spans']\n",
    "        facecolor = d[ax]['facecolor']\n",
    "        spines = d[ax]['spines']\n",
    "        axes[ax] = plt.subplot2grid(shape=grid_shape, loc=loc, rowspan=rowspan, colspan=colspan, facecolor=facecolor, xticks=[], yticks=[])\n",
    "        for sp in axes[ax].spines.values():\n",
    "            sp.set_visible(spines)\n",
    "\n",
    "    # draw the top brace\n",
    "    x,y = range_brace(0, 1)\n",
    "    axes['ax_top_brace'].set_xlim(0,1)\n",
    "    axes['ax_top_brace'].set_ylim(0,1)\n",
    "    axes['ax_top_brace'].plot(x, y,'-', clip_on=False)\n",
    "\n",
    "    # draw the left brace\n",
    "    x,y = range_brace(0, 1)\n",
    "    axes['ax_left_brace'].set_xlim(0,1)\n",
    "    axes['ax_left_brace'].set_ylim(0,1)    \n",
    "    base = plt.gca().transData\n",
    "    rot = transforms.Affine2D().rotate_deg_around(.5, .5, 90)\n",
    "    axes['ax_left_brace'].plot(x, y,'-', clip_on=False, transform=rot+base)\n",
    "\n",
    "    typexx = ['ax', 'coord', 'text', 'align', 'fontsize', 'weight', 'color', 'path_effectsx', 'rotationx']\n",
    "    text_list = [\n",
    "        ['ax_n2',(.5, .7), 'Total', ('center', 'center'), 20, 'normal', 'black', False, 0], \n",
    "        ['ax_n2',(.5, .3), f'{(tn+tp+fn+fp):,.0f}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_predicted_negative',(.5, .5), 'Negative', ('center', 'center'), 15, 'bold', 'black', False, 0],\n",
    "        ['ax_predicted_positive',(.5, .5), 'Positive', ('center', 'center'), 15, 'bold', 'black', False, 0],\n",
    "        ['ax_actual_negative',(.5, .5), 'Negative', ('center', 'center'), 15, 'bold', 'black', False, 0],\n",
    "        ['ax_actual_positive',(.5, .5), 'Positive', ('center', 'center'), 15, 'bold', 'black', False, 0],\n",
    "        ['ax_true_negative',(.5, .7), 'True Negative (TN)', ('center', 'center'), 18, 'normal', 'green', True, 0],\n",
    "        ['ax_true_negative',(.5, .3), f'{tn:,.0f}', ('center', 'center'), 18, 'normal', 'green', True, 0],\n",
    "        ['ax_false_positive',(.5, .8), 'False Positive (FP))', ('center', 'center'), 18, 'normal', 'red', True, 0],\n",
    "        ['ax_false_positive',(.5, .55), '(Type I Error)', ('center', 'center'), 16, 'normal', 'darkred', False, 0],\n",
    "        ['ax_false_positive',(.5, .3), f'{fp:,.0f}', ('center', 'center'), 20, 'normal', 'red', False, 0],\n",
    "        ['ax_false_negative',(.5, .8), 'False Negative (FN)', ('center', 'center'), 18, 'normal', 'red', True, 0],\n",
    "        ['ax_false_negative',(.5, .55), '(Type II Error)', ('center', 'center'), 16, 'normal', 'darkred', False, 0],\n",
    "        ['ax_false_negative',(.5, .3), f'{fn:,.0f}', ('center', 'center'), 20, 'normal', 'red', False, 0],\n",
    "        ['ax_true_positive',(.5, .7), 'True Positive (TP)', ('center', 'center'), 18, 'normal', 'green', True, 0],\n",
    "        ['ax_true_positive',(.5, .3), f'{tp:,.0f}', ('center', 'center'), 20, 'normal', 'green', False, 0],\n",
    "        ['ax_total_predicted_negative',(.5, .7), 'Total Predicted Negative', ('center', 'center'), 14, 'normal', 'black', False, 0],\n",
    "        ['ax_total_predicted_negative',(.5, .3), f'{(tn+fn):,.0f}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_total_predicted_positive',(.5, .7), 'Total Predicted Positive', ('center', 'center'), 14, 'normal', 'black', False, 0],\n",
    "        ['ax_total_predicted_positive',(.5, .3), f'{(tp+fp):,.0f}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_total_actual_negative',(.5, .7), 'Total\\nActual Negative', ('center', 'center'), 14, 'normal', 'black', False, 0],\n",
    "        ['ax_total_actual_negative',(.5, .3), f'{(tn+fp):,.0f}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_total_actual_positive',(.5, .7), 'Total\\nActual Positive', ('center', 'center'), 14, 'normal', 'black', False, 0],\n",
    "        ['ax_total_actual_positive',(.5, .3), f'{(tp+fn):,.0f}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_precision',(.5, .8), 'Precision\\nPositive Predictive Value', ('center', 'center'), 15, 'normal', 'black', False, 0],\n",
    "        ['ax_precision',(.5, .45), r'$\\frac{TP}{TP+FP}$', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_precision',(.5, .1), f'{tp / (tp+fp):.2%}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_negative_predictive_value',(.5, .8), 'Negative Predictive Value', ('center', 'center'), 15, 'normal', 'black', False, 0],\n",
    "        ['ax_negative_predictive_value',(.5, .45), r'$\\frac{TN}{TN+FN}$', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_negative_predictive_value',(.5, .1), f'{tn / (tn+fn):.2%}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_accuracy',(.5, .8), 'Accuracy', ('center', 'center'), 15, 'normal', 'black', False, 0],\n",
    "        ['ax_accuracy',(.5, .45), r'$\\frac{TP+TN}{TP+TN+FP+FN}$', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_accuracy',(.5, .1), f'{(tn+tp) / (tn+tp+fn+fp):.2%}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_f1',(.5, .8), 'F1 Score', ('center', 'center'), 15, 'normal', 'black', False, 0],\n",
    "        ['ax_f1',(.5, .45), r'$2\\left(\\frac{(Precision)(Recall)}{Precision + Recall}\\right)$', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_f1',(.5, .1), f'{2*(((tp/(tp+fp)) * (tp/(tp+fn))) / ((tp/(tp+fp)) + (tp/(tp+fn)))):.2%}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_specificity',(.5, .8), 'True Negative Rate (TNR)\\nSpecificity', ('center', 'center'), 15, 'normal', 'black', False, 0],\n",
    "        ['ax_specificity',(.5, .425), r'$\\frac{TN}{TN+FP}$', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_specificity',(.5, .1), f'{(tn) / (tn+fp):.2%}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_sensitivity',(.5, .8), 'True Positive Rate (TPR)\\nSensitivity or Recall', ('center', 'center'), 15, 'normal', 'black', False, 0],\n",
    "        ['ax_sensitivity',(.5, .425), r'$\\frac{TP}{TP+FN}$', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_sensitivity',(.5, .1), f'{(tp) / (tp+fn):.2%}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_predicted_class',(.5, .5), 'Predicted Class', ('center', 'center'), 15, 'bold', 'black', False, 0],\n",
    "        ['ax_actual_class',(.5, .5), 'Actual Class', ('center', 'center'), 15, 'bold', 'black', False, 90]]\n",
    "\n",
    "    d2 = {}\n",
    "    for ax, text_list in zip(range(len(text_list)), text_list):\n",
    "        d2[ax] = dict(zip(typexx, text_list))\n",
    "\n",
    "    for key, value in d2.items():\n",
    "        x, y = value['coord']\n",
    "        txt = value['text']\n",
    "        va, ha = value['align']\n",
    "        fontsize = value['fontsize']\n",
    "        weight = value['weight']\n",
    "        color = value['color']\n",
    "        path_effectsx = value['path_effectsx']\n",
    "        if path_effectsx == True:\n",
    "            path_effects_var = [path_effects.withSimplePatchShadow()]\n",
    "        else:\n",
    "            path_effects_var = False\n",
    "        rotationx = value['rotationx']\n",
    "\n",
    "        axes[d2[key]['ax']].text(x=x, y=y, s=txt, va=va, ha=ha, fontsize=fontsize, weight=weight, color=color, path_effects=path_effects_var, rotation=rotationx)\n",
    "\n",
    "    plt.suptitle('Confusion Matrix Plus', fontsize=30)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    print('')\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "@time_it\n",
    "def show_errors_gt_ff(k=2, filename=None, model=False):\n",
    "    assert Path.cwd().name == 'intermediary reports'\n",
    "\n",
    "    if filename == None:\n",
    "        files = df_mtcnn['path_file'].unique()\n",
    "        if len(files) > k:  # sample w/o replacement if we have enough, otherwise use replacement\n",
    "            files = random.sample(list(files), k)  # sample w/o replacement\n",
    "        else:\n",
    "            files = random.choices(list(files), k)  # sample w/ replacement\n",
    "    else:\n",
    "        files = list(df_gt[df_gt['file_only']==filename]['source_file'].unique())\n",
    "\n",
    "    for file in files:\n",
    "        ret, image, pct_resize = read_image(file, True)\n",
    "        if not ret:\n",
    "            assert 1 == 2\n",
    "\n",
    "        # start by drawing all the gt faces in green\n",
    "        df = df_gt[df_gt['source_file']==file]\n",
    "        for index, row in df.iterrows():\n",
    "            cv2.circle(image, (int(row['gt_x'] * pct_resize), int(row['gt_y'] * pct_resize)), 25,\n",
    "               (102, 255, 0), 3) # green\n",
    "    \n",
    "        df = df_mtcnn[df_mtcnn['path_file']==file]\n",
    "        for index, row in df.iterrows():\n",
    "            # draw orange circle over green circle if confirmed\n",
    "            if row['confirmed_gt']:\n",
    "                cv2.circle(image, (int(row['gt_x'] * pct_resize), int(row['gt_y'] * pct_resize)), 25,\n",
    "                           (0, 155, 255), 3) # orange\n",
    "                \n",
    "                cv2.rectangle(image,\n",
    "                              (int(row['x1'] * pct_resize), int(row['y1'] * pct_resize)),\n",
    "                              (int((row['x1'] + row['w']) * pct_resize), int((row['y1'] + row['h'])* pct_resize)),\n",
    "                              (0, 155, 255), 3) # orange\n",
    "            else:\n",
    "                cv2.rectangle(image,\n",
    "                              (int(row['x1'] * pct_resize), int(row['y1'] * pct_resize)),\n",
    "                              (int((row['x1'] + row['w']) * pct_resize), int((row['y1'] + row['h'])* pct_resize)),\n",
    "                              (102, 255, 0), 3) # orange\n",
    "            if model:\n",
    "                if row['bad_faces_model'] == 0:\n",
    "                    cv2.rectangle(image,\n",
    "                              (int(row['x1'] * pct_resize), int(row['y1'] * pct_resize)),\n",
    "                              (int((row['x1'] + row['w']) * pct_resize), int((row['y1'] + row['h'])* pct_resize)),\n",
    "                              (0, 0, 255), 3) # red\n",
    "                    \n",
    "\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        plt.title(file.name + '\\n' + str(image.shape))\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "face alignment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = cv2.imread(str(path))\n",
    "    return img\n",
    "\n",
    "\n",
    "def rotate_point(origin, point, angle):\n",
    "    ox, oy = origin\n",
    "    px, py = point\n",
    "\n",
    "    qx = ox + np.cos(angle) * (px - ox) - np.sin(angle) * (py - oy)\n",
    "    qy = oy + np.sin(angle) * (px - ox) + np.cos(angle) * (py - oy)\n",
    "    return qx, qy\n",
    "\n",
    "def cosine_formula(length_line1, length_line2, length_line3):\n",
    "    cos_a = -(length_line3 ** 2 - length_line2 ** 2 - length_line1 ** 2) / (2 * length_line2 * length_line1)\n",
    "    return cos_a\n",
    "\n",
    "def is_between(point1, point2, point3, extra_point):\n",
    "    c1 = (point2[0] - point1[0]) * (extra_point[1] - point1[1]) - (point2[1] - point1[1]) * (extra_point[0] - point1[0])\n",
    "    c2 = (point3[0] - point2[0]) * (extra_point[1] - point2[1]) - (point3[1] - point2[1]) * (extra_point[0] - point2[0])\n",
    "    c3 = (point1[0] - point3[0]) * (extra_point[1] - point3[1]) - (point1[1] - point3[1]) * (extra_point[0] - point3[0])\n",
    "    if (c1 < 0 and c2 < 0 and c3 < 0) or (c1 > 0 and c2 > 0 and c3 > 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def distance(a, b):\n",
    "    return np.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
    "\n",
    "def rotate_opencv(img, nose_center, angle):\n",
    "    M = cv2.getRotationMatrix2D(nose_center, angle, 1)\n",
    "    rotated = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_CUBIC)\n",
    "    return rotated\n",
    "\n",
    "def rotation_detection_opencv(face_file, img, mode, show=False):\n",
    "    print('--',face_file)\n",
    "#     nose_cascade = cv2.CascadeClassifier('haarcascade_mcs_nose.xml')\n",
    "#     eyes_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "#     fase_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "#     nose_rects = nose_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "#     eyes_rects = eyes_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "#     face_rects = fase_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "#     length_eyes = len(eyes_rects)\n",
    "\n",
    "#     if length_eyes == 2 and len(nose_rects) != 0 and len(face_rects) != 0:\n",
    "#         nose, right_eye, left_eye = get_eyes_nose(eyes_rects, nose_rects)\n",
    "#     else:\n",
    "#         print(\"Couldn't determine eyes/nose\")\n",
    "#         return img\n",
    "    df2 = df_mtcnn[df_mtcnn['face_file']==face_file]\n",
    "    print('***',len(df2))\n",
    "    return img\n",
    "    fd = df2.to_dict('r')[0]\n",
    "    center_of_forehead = (int((fd['face_image_right_eye'][0] + fd['face_image_left_eye'][0]) / 2), int((fd['face_image_right_eye'][1] + fd['face_image_left_eye'][1]) / 2))\n",
    "    cv2.circle(img, fd['face_image_right_eye'], 5, (255,0,0), 2)\n",
    "    cv2.circle(img, fd['face_image_left_eye'], 5, (255,0,0), 2)\n",
    "    cv2.circle(img, fd['face_image_nose'], 5, (255,0,0), 2)\n",
    "    cv2.circle(img, center_of_forehead, 5, (0,0,255), 2)\n",
    "\n",
    "    print(center_of_forehead)\n",
    "    \n",
    "#     center_pred = (int((face_rects[0][0] + face_rects[0][2]) / 2), int((face_rects[0][1] + face_rects[0][1]) / 2))\n",
    "    center_pred = (int((image.shape[1] / 2)),0)\n",
    "    length_line1 = distance(center_of_forehead, fd['face_image_nose'])\n",
    "    length_line2 = distance(center_pred, fd['face_image_nose'])\n",
    "    length_line3 = distance(center_pred, center_of_forehead)\n",
    "    \n",
    "    cv2.line(img, fd['face_image_nose'], center_of_forehead, (255,0,0), 5)\n",
    "    cv2.line(img, center_of_forehead, center_pred, (0,255,0), 5)\n",
    "    cv2.line(img, center_pred, fd['face_image_nose'], (0,0,255), 5)\n",
    "    \n",
    "    img2 = imutils.resize(img, width=1000)\n",
    "    cv2.imshow('x', img2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    cos_a = cosine_formula(length_line1, length_line2, length_line3)\n",
    "    angle = np.arccos(cos_a)\n",
    "    rotated_point = rotate_point(fd['face_image_nose'], center_of_forehead, angle)\n",
    "    rotated_point = (int(rotated_point[0]), int(rotated_point[1]))\n",
    "    if is_between(fd['face_image_nose'], center_of_forehead, center_pred, rotated_point):\n",
    "        angle = np.degrees(-angle)\n",
    "    else:\n",
    "        angle = np.degrees(angle)\n",
    "    if mode:\n",
    "        img = rotate_opencv(img, fd['face_image_nose'], angle)\n",
    "    else:\n",
    "        img = Image.fromarray(img)\n",
    "        img = np.array(img.rotate(angle))\n",
    "    if show:\n",
    "        show_img(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def save_img(path, img):\n",
    "    cv2.imwrite(path, img)\n",
    "\n",
    "\n",
    "def face_alignment(face_file, img):\n",
    "#     print('**',face_file)\n",
    "#     img = load_img(file)\n",
    "    img = rotation_detection_opencv(face_file, img, True, False)\n",
    "#     img = rotation_detection_opencv(img, args.rotation_mode, args.show)\n",
    "#     save_img(args.path_to_save, img)\n",
    "#     cv2.imshow('x', img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms to try\n",
    "classification_algos_name = [\n",
    "    \"KNeighborsClassifier\",\n",
    "    \"GaussianNB\",\n",
    "    \"DecisionTreeClassifier\",\n",
    "    \"ExtraTreeClassifier\",\n",
    "    \"RandomForestClassifier\",\n",
    "    \"AdaBoostClassifier\",\n",
    "    \"GradientBoostingClassifier\",\n",
    "    \"XGBClassifier\",\n",
    "    \"LGBMClassifier\",\n",
    "]\n",
    "\n",
    "classification_algos = [\n",
    "    KNeighborsClassifier(20),\n",
    "    GaussianNB(),\n",
    "    DecisionTreeClassifier(),\n",
    "    ExtraTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    XGBClassifier(),\n",
    "    LGBMClassifier(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common variables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common variables used throughout the notebook\n",
    "random.seed(14)\n",
    "\n",
    "DATA_DIR = Path('../../data/')\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth=6)\n",
    "\n",
    "start_all = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables from previous notebooks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = load_obj('df_s3')\n",
    "df_harr = load_obj('df_harr3')\n",
    "df_mtcnn = load_obj('df_mtcnn3')\n",
    "df_gt = load_obj('df_gt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_name(df):\n",
    "    df['name'] = df['face_file'].parts[-2]\n",
    "    return df['name']\n",
    "    \n",
    "\n",
    "df_target = pd.DataFrame(list(Path('../../data/02_target_faces/').rglob('*.jpg')), columns=['face_file'])\n",
    "df_target['name'] = ''\n",
    "df_target['name'] = df_target.apply(get_name, axis=1)\n",
    "len(df_target['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face recognizer...\n",
      "-- ..\\..\\data\\02_target_faces\\Elijah_W\\L___0174_faceno_0001.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Elijah_W\\L___0174_faceno_0001.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Elijah_W\\L___0177-2_faceno_0010.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Elijah_W\\L___0177_faceno_0007.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Elijah_W\\L___0212_faceno_0006.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Elijah_W\\L___0214_faceno_0007.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Elijah_W\\L___0218_faceno_0002.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Elijah_W\\L___0222_faceno_0001.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Elijah_W\\L___0225_faceno_0000.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Elijah_W\\R___0890_faceno_0000.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Elijah_W\\TAW_0836_faceno_0003.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Elijah_W\\TAW_0861_faceno_0017.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Elijah_W\\TAW_0866_faceno_0003.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Sophie_W\\L___0063_faceno_0009.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Sophie_W\\L___0066_faceno_0008.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Sophie_W\\L___0068_faceno_0004.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Sophie_W\\L___0069_faceno_0002.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Sophie_W\\L___0071_faceno_0000.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Sophie_W\\L___0079_faceno_0001.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Sophie_W\\L___0080_faceno_0002.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Sophie_W\\L___0081_faceno_0003.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0280_faceno_0005.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0280_faceno_0006.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0280_faceno_0007.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0280_faceno_0008.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0280_faceno_0009.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0280_faceno_0010.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0280_faceno_0011.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0280_faceno_0012.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0330_faceno_0000.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0330_faceno_0001.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0330_faceno_0002.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0330_faceno_0003.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0373_faceno_0000.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0373_faceno_0001.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0426_faceno_0000.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0426_faceno_0002.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0000.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0001.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0002.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0003.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0004.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0005.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0006.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0007.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0008.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0010.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0011.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0012.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0013.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0015.jpg\n",
      "*** 0\n",
      "-- ..\\..\\data\\02_target_faces\\Unknown\\TAW_0475_faceno_0016.jpg\n",
      "*** 0\n"
     ]
    }
   ],
   "source": [
    "# USAGE\n",
    "# python extract_embeddings.py --dataset dataset --embeddings output/embeddings.pickle \\\n",
    "#\t--detector face_detection_model --embedding-model openface_nn4.small2.v1.t7\n",
    "\n",
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "# load our serialized face embedding model from disk\n",
    "print(\"[INFO] loading face recognizer...\")\n",
    "embedder = cv2.dnn.readNetFromTorch('../../data/10_other/models/openface_nn4.small2.v1.t7')\n",
    "\n",
    "knownEmbeddings = []\n",
    "knownNames = []\n",
    "\n",
    "# initialize the total number of faces processed\n",
    "total = 0\n",
    "\n",
    "def get_face_embedding(df):\n",
    "    image = cv2.imread(str(df['face_file']))\n",
    "#     print(df['face_file'])\n",
    "    image = face_alignment(df['face_file'], image)\n",
    "    image = imutils.resize(image, width=600)\n",
    "    (h, w) = image.shape[:2]    \n",
    "    faceBlob = cv2.dnn.blobFromImage(image, 1.0 / 255,\n",
    "        (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "    embedder.setInput(faceBlob)\n",
    "    vec = embedder.forward()\n",
    "    return vec.flatten()\n",
    "    \n",
    "df_target['vec'] = df_target.apply(get_face_embedding, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face_file</th>\n",
       "      <th>name</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data\\02_target_faces\\Elijah_W\\L___0174_f...</td>\n",
       "      <td>Elijah_W</td>\n",
       "      <td>[-0.013208638, 0.049533945, 0.02361381, 0.0047...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data\\02_target_faces\\Elijah_W\\L___0177-2...</td>\n",
       "      <td>Elijah_W</td>\n",
       "      <td>[0.037435014, 0.018378586, -0.05540103, 0.0075...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           face_file      name  \\\n",
       "0  ..\\..\\data\\02_target_faces\\Elijah_W\\L___0174_f...  Elijah_W   \n",
       "1  ..\\..\\data\\02_target_faces\\Elijah_W\\L___0177-2...  Elijah_W   \n",
       "\n",
       "                                                 vec  \n",
       "0  [-0.013208638, 0.049533945, 0.02361381, 0.0047...  \n",
       "1  [0.037435014, 0.018378586, -0.05540103, 0.0075...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face_file</th>\n",
       "      <th>no_face_file</th>\n",
       "      <th>path_file</th>\n",
       "      <th>faceno</th>\n",
       "      <th>faceno_int</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>w</th>\n",
       "      <th>...</th>\n",
       "      <th>nf_dominant_color</th>\n",
       "      <th>nf_dominant_color_R</th>\n",
       "      <th>nf_dominant_color_G</th>\n",
       "      <th>nf_dominant_color_B</th>\n",
       "      <th>nf_average_color</th>\n",
       "      <th>nf_average_color_R</th>\n",
       "      <th>nf_average_color_G</th>\n",
       "      <th>nf_average_color_B</th>\n",
       "      <th>nf_pct_skin_tone</th>\n",
       "      <th>bad_faces_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data\\01_source_photos\\2018-11-10\\mtcnn_f...</td>\n",
       "      <td>..\\..\\data\\01_source_photos\\2018-11-10\\mtcnn_n...</td>\n",
       "      <td>..\\..\\data\\01_source_photos\\2018-11-10\\TAW_028...</td>\n",
       "      <td>0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1327</td>\n",
       "      <td>1427</td>\n",
       "      <td>1418</td>\n",
       "      <td>1541</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>(226.61987, 227.5004, 231.56941)</td>\n",
       "      <td>226.619873</td>\n",
       "      <td>227.500397</td>\n",
       "      <td>231.569412</td>\n",
       "      <td>(226.6848852901485, 227.48380566801615, 231.59...</td>\n",
       "      <td>226.684885</td>\n",
       "      <td>227.483806</td>\n",
       "      <td>231.592539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data\\01_source_photos\\2018-11-10\\mtcnn_f...</td>\n",
       "      <td>..\\..\\data\\01_source_photos\\2018-11-10\\mtcnn_n...</td>\n",
       "      <td>..\\..\\data\\01_source_photos\\2018-11-10\\TAW_028...</td>\n",
       "      <td>0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2120</td>\n",
       "      <td>1257</td>\n",
       "      <td>2248</td>\n",
       "      <td>1420</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>(86.914024, 98.04527, 125.6689)</td>\n",
       "      <td>86.914024</td>\n",
       "      <td>98.045273</td>\n",
       "      <td>125.668900</td>\n",
       "      <td>(104.24602185582819, 111.03048312883439, 117.1...</td>\n",
       "      <td>104.246022</td>\n",
       "      <td>111.030483</td>\n",
       "      <td>117.145370</td>\n",
       "      <td>0.104822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           face_file  \\\n",
       "0  ..\\..\\data\\01_source_photos\\2018-11-10\\mtcnn_f...   \n",
       "1  ..\\..\\data\\01_source_photos\\2018-11-10\\mtcnn_f...   \n",
       "\n",
       "                                        no_face_file  \\\n",
       "0  ..\\..\\data\\01_source_photos\\2018-11-10\\mtcnn_n...   \n",
       "1  ..\\..\\data\\01_source_photos\\2018-11-10\\mtcnn_n...   \n",
       "\n",
       "                                           path_file faceno  faceno_int    x1  \\\n",
       "0  ..\\..\\data\\01_source_photos\\2018-11-10\\TAW_028...   0000           0  1327   \n",
       "1  ..\\..\\data\\01_source_photos\\2018-11-10\\TAW_028...   0001           1  2120   \n",
       "\n",
       "     y1    x2    y2    w  ...                 nf_dominant_color  \\\n",
       "0  1427  1418  1541   91  ...  (226.61987, 227.5004, 231.56941)   \n",
       "1  1257  2248  1420  128  ...   (86.914024, 98.04527, 125.6689)   \n",
       "\n",
       "   nf_dominant_color_R  nf_dominant_color_G  nf_dominant_color_B  \\\n",
       "0           226.619873           227.500397           231.569412   \n",
       "1            86.914024            98.045273           125.668900   \n",
       "\n",
       "                                    nf_average_color  nf_average_color_R  \\\n",
       "0  (226.6848852901485, 227.48380566801615, 231.59...          226.684885   \n",
       "1  (104.24602185582819, 111.03048312883439, 117.1...          104.246022   \n",
       "\n",
       "   nf_average_color_G nf_average_color_B nf_pct_skin_tone bad_faces_model  \n",
       "0          227.483806         231.592539         0.000000               1  \n",
       "1          111.030483         117.145370         0.104822               1  \n",
       "\n",
       "[2 rows x 52 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mtcnn.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Elijah_W', 'Sophie_W', 'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df_target[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face_file</th>\n",
       "      <th>name</th>\n",
       "      <th>vec</th>\n",
       "      <th>vec_001</th>\n",
       "      <th>vec_002</th>\n",
       "      <th>vec_003</th>\n",
       "      <th>vec_004</th>\n",
       "      <th>vec_005</th>\n",
       "      <th>vec_006</th>\n",
       "      <th>vec_007</th>\n",
       "      <th>...</th>\n",
       "      <th>vec_119</th>\n",
       "      <th>vec_120</th>\n",
       "      <th>vec_121</th>\n",
       "      <th>vec_122</th>\n",
       "      <th>vec_123</th>\n",
       "      <th>vec_124</th>\n",
       "      <th>vec_125</th>\n",
       "      <th>vec_126</th>\n",
       "      <th>vec_127</th>\n",
       "      <th>vec_128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data\\02_target_faces\\Elijah_W\\L___0174_f...</td>\n",
       "      <td>Elijah_W</td>\n",
       "      <td>[-0.013208638, 0.049533945, 0.02361381, 0.0047...</td>\n",
       "      <td>-0.013209</td>\n",
       "      <td>0.049534</td>\n",
       "      <td>0.023614</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>-0.107257</td>\n",
       "      <td>0.179725</td>\n",
       "      <td>-0.011575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062234</td>\n",
       "      <td>0.102035</td>\n",
       "      <td>0.028108</td>\n",
       "      <td>-0.098982</td>\n",
       "      <td>0.104058</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.061921</td>\n",
       "      <td>0.05224</td>\n",
       "      <td>0.169577</td>\n",
       "      <td>0.071947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data\\02_target_faces\\Elijah_W\\L___0177-2...</td>\n",
       "      <td>Elijah_W</td>\n",
       "      <td>[0.037435014, 0.018378586, -0.05540103, 0.0075...</td>\n",
       "      <td>0.037435</td>\n",
       "      <td>0.018379</td>\n",
       "      <td>-0.055401</td>\n",
       "      <td>0.007573</td>\n",
       "      <td>-0.050066</td>\n",
       "      <td>0.144915</td>\n",
       "      <td>-0.050973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.105963</td>\n",
       "      <td>-0.020749</td>\n",
       "      <td>-0.014761</td>\n",
       "      <td>0.151101</td>\n",
       "      <td>-0.039718</td>\n",
       "      <td>-0.016223</td>\n",
       "      <td>0.07785</td>\n",
       "      <td>0.129358</td>\n",
       "      <td>0.012286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           face_file      name  \\\n",
       "0  ..\\..\\data\\02_target_faces\\Elijah_W\\L___0174_f...  Elijah_W   \n",
       "1  ..\\..\\data\\02_target_faces\\Elijah_W\\L___0177-2...  Elijah_W   \n",
       "\n",
       "                                                 vec   vec_001   vec_002  \\\n",
       "0  [-0.013208638, 0.049533945, 0.02361381, 0.0047... -0.013209  0.049534   \n",
       "1  [0.037435014, 0.018378586, -0.05540103, 0.0075...  0.037435  0.018379   \n",
       "\n",
       "    vec_003   vec_004   vec_005   vec_006   vec_007  ...   vec_119   vec_120  \\\n",
       "0  0.023614  0.004732 -0.107257  0.179725 -0.011575  ...  0.062234  0.102035   \n",
       "1 -0.055401  0.007573 -0.050066  0.144915 -0.050973  ...  0.001033  0.105963   \n",
       "\n",
       "    vec_121   vec_122   vec_123   vec_124   vec_125  vec_126   vec_127  \\\n",
       "0  0.028108 -0.098982  0.104058 -0.000022  0.061921  0.05224  0.169577   \n",
       "1 -0.020749 -0.014761  0.151101 -0.039718 -0.016223  0.07785  0.129358   \n",
       "\n",
       "    vec_128  \n",
       "0  0.071947  \n",
       "1  0.012286  \n",
       "\n",
       "[2 rows x 131 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['vec_'+str(i+1).zfill(3) for i in range(128)]\n",
    "# df_x = pd.DataFrame(df_target['vec'].values.tolist(), columns=cols)\n",
    "df_target = pd.concat([df_target, pd.DataFrame(df_target['vec'].values.tolist(), columns=cols)], axis=1)\n",
    "df_target.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "train_cols = [col for col in df_target.columns if col.startswith('vec_')]\n",
    "print(len(train_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[INFO] training model...\")\n",
    "recognizer = SVC(C=1.0, kernel=\"linear\", probability=True)\n",
    "recognizer.fit(df_target[train_cols], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "face_list = []\n",
    "name_list = []\n",
    "files = df_mtcnn['face_file']\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "#     if i > 50:\n",
    "#         break\n",
    "    face = cv2.imread(str(file))\n",
    "    face = imutils.resize(face, width=600)\n",
    "    (h, w) = face.shape[:2]\n",
    "\n",
    "    # apply OpenCV's deep learning-based face detector to localize\n",
    "    # faces in the input image\n",
    "    # detector.setInput(imageBlob)\n",
    "    # detections = detector.forward()\n",
    "\n",
    "    faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255, (96, 96),\n",
    "        (0, 0, 0), swapRB=True, crop=False)\n",
    "    embedder.setInput(faceBlob)\n",
    "    vec = embedder.forward()\n",
    "\n",
    "    preds = recognizer.predict_proba(vec)[0]\n",
    "    j = np.argmax(preds)\n",
    "    proba = preds[j]\n",
    "    name = le.classes_[j]\n",
    "    \n",
    "#     print(preds)\n",
    "#     if preds[np.argmax(preds)] > .90:\n",
    "    if preds[0] > .80:\n",
    "        face_list.append(face)\n",
    "        name_list.append(name)\n",
    "\n",
    "print(len(face_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elijah_W' 'Sophie_W' 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, face in enumerate(face_list):\n",
    "    cv2.imshow(name_list[i], face)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "time.sleep(1)\n",
    "print(f'{time.strftime(\"%H:%M:%S\", time.gmtime(int(time.time() - start)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{time.strftime(\"%H:%M:%S\", time.gmtime(int(time.time() - start_all)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mtcnn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
