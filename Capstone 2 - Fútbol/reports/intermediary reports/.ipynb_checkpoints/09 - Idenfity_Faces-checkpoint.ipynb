{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FÃºtbol Match Highlights<br>\n",
    "Identify Faces - Capstone 2<br>\n",
    "Tom Widdows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Housekeeping..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../code')\n",
    "import settings as s\n",
    "\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import imutils\n",
    "import lightgbm  as  lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from matplotlib.colors import rgb_to_hsv\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter, PercentFormatter, StrMethodFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw \n",
    "import pprint\n",
    "import random\n",
    "from scipy.stats import t, norm, ttest_ind, ttest_rel, zscore\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score, classification_report\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    SCORERS,  # # sorted(SCORERS.keys())\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    plot_confusion_matrix,\n",
    "    roc_curve\n",
    ")\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, LassoCV\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, binarize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from utility import read_image\n",
    "import time\n",
    "\n",
    "start_all = time.time()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decorators..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decorator to help with timing functions\n",
    "def time_it(func):\n",
    "    \"\"\"Decorator function to time functions in Jupyter Notebook\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f'{time.strftime(\"%H:%M:%S\", time.gmtime(int(time.time() - start)))}')\n",
    "        return result\n",
    "    return wrapper    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility functions\n",
    "\n",
    "# save pickle\n",
    "def save_obj(obj, name):\n",
    "    import pickle\n",
    "    with open(DATA_DIR / '10_other/objects' / str(name + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# load pickle\n",
    "def load_obj(name ):\n",
    "    import pickle\n",
    "    with open(DATA_DIR / '10_other/objects' / str(name + '.pkl'), 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "\n",
    "# iqr to calculate max of boxplot\n",
    "def max_y_iqr(x):\n",
    "    q75, q25 = np.percentile(x, [75 ,25])\n",
    "    iqr = q75 - q25\n",
    "    y_max = np.percentile(x, [75]) + (iqr*2)\n",
    "    return(y_max)\n",
    "\n",
    "\n",
    "# print blank lines\n",
    "def bl(qty=1):\n",
    "    for l in range(qty):\n",
    "        print()\n",
    "    \n",
    "\n",
    "def merge_dicts(*dict_args):\n",
    "    \"\"\"\n",
    "    Given any number of dicts, shallow copy and merge into a new dict,\n",
    "    precedence goes to key value pairs in latter dicts.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for dictionary in dict_args:\n",
    "        result.update(dictionary)\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return best thresholds\n",
    "def cutoff_youdens_j(fpr,tpr,thresholds):\n",
    "    j_scores = tpr-fpr\n",
    "    j_ordered = sorted(zip(j_scores,thresholds))\n",
    "    return j_ordered[-1][1]\n",
    "\n",
    "# get a list of all the faces and show a sample\n",
    "@time_it\n",
    "def show_faces(faces):\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "    faces = faces.values.tolist()\n",
    "    if len(faces) > 10:  # sample w/o replacement if we have enough, otherwise use replacement\n",
    "        faces = random.sample(faces, 10)  # sample w/o replacement\n",
    "    else:\n",
    "        faces = random.choices(faces, k=10)  # sample w/ replacement\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    for i, file in enumerate(faces):\n",
    "        img = plt.imread(str(file))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        plt.show()        \n",
    "        \n",
    "# get a list of all the faces and show a sample\n",
    "def show_non_faces(df):\n",
    "    faces = [p for p in df['no_face_file']]\n",
    "    if len(faces) > 64:  # sample w/o replacement if we have enough, otherwise use replacement\n",
    "        faces = random.sample(faces, 64)  # sample w/o replacement\n",
    "    else:\n",
    "        faces = random.choices(faces, k=64)  # sample w/ replacement\n",
    "\n",
    "    fig, axs = plt.subplots(8, 8, figsize=(12, 12))\n",
    "    axs = axs.flatten()\n",
    "    for i, file in enumerate(faces):\n",
    "        img = plt.imread(file)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].imshow(img)\n",
    "        \n",
    "        \n",
    "# plot histogram of predicted probability\n",
    "def pred_prob_hist(X_valid, bins=8, xlabel='positive', cutoff=0.5):\n",
    "    plt.hist(y_pred_prob, bins=bins)\n",
    "    plt.xlim(0,1)\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    ax.xaxis.set_major_formatter(PercentFormatter(1))\n",
    "    ax.axvline(x=cutoff, ymin=0, ymax=1, color='r', linewidth=3,  linestyle='--')\n",
    "    plt.title(\"Histogram of predicted probabilities\")\n",
    "    plt.xlabel(\"Predicted probability of \"+xlabel)\n",
    "    plt.ylabel('Frequency');\n",
    "    colors = ['darkred']\n",
    "    lines = [Line2D([0], [0], color=c, linewidth=3, linestyle='--') for c in colors]\n",
    "    labels = ['Cutoff']\n",
    "    plt.legend(lines, labels)\n",
    "    plt.show();\n",
    "    bl()\n",
    "\n",
    "    \n",
    "# plot feature importances\n",
    "def feat_imp_plot(df, model, n_features, max_features=30):\n",
    "    n_features = min(n_features, max_features)\n",
    "    d = dict(zip(df.columns, model.feature_importances_))\n",
    "    ss = sorted(d, key=d.get, reverse=True)\n",
    "    top_names = ss[0:n_features]\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(n_features), [d[i] for i in top_names], color=\"r\", align=\"center\")\n",
    "    plt.xlim(-1, n_features)\n",
    "    plt.xticks(range(n_features), top_names, rotation=\"vertical\")\n",
    "\n",
    "    \n",
    "# draw diag line\n",
    "def abline(slope, intercept):\n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '--')\n",
    "\n",
    "\n",
    "# plot roc curve\n",
    "def plot_roc_curve(y_valid, y_pred_prob):\n",
    "    fpr, tpr, thresholds = roc_curve(y_valid, y_pred_prob.ravel())\n",
    "    optimal_cutoff = cutoff_youdens_j(fpr,tpr,thresholds)\n",
    "    y_pred_class = binarize(y_pred_prob.reshape(1,-1), optimal_cutoff) \n",
    "    tn, fp, fn, tp = confusion_matrix(y_valid, y_pred_class.ravel()).ravel()\n",
    "    false_positive_rate = fp / (fp + tn)\n",
    "    true_positive_rate = tp / (tp + fn)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_formatter(PercentFormatter(1))\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "    plt.xticks(fontsize=12, rotation=0)\n",
    "    plt.yticks(fontsize=12, rotation=0)\n",
    "    plt.title('ROC curve\\n', fontsize=16)\n",
    "    plt.xlabel('False Positive Rate\\nFP / (FP + TN)', fontsize=14)  # : (1 - Specificity)\n",
    "    plt.ylabel('True Positive Rate (Recall)\\nTP / (TP + FN)', fontsize=14)  # : (Recall)\n",
    "    plt.grid(True)\n",
    "    abline(slope=1,intercept=0)\n",
    "    ax.axvline(x=false_positive_rate, ymin=0, ymax=true_positive_rate, color='r', linestyle='--')\n",
    "    ax.axhline(y=true_positive_rate, xmin=0, xmax=false_positive_rate, color='r', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('images/ROC_Curve')\n",
    "    return optimal_cutoff\n",
    "\n",
    "\n",
    "# plot confusion matrix plus\n",
    "def plot_cm_plus(tn, fp, fn, tp):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patheffects as path_effects\n",
    "    from matplotlib import transforms\n",
    "    import numpy as np\n",
    "\n",
    "    def range_brace(x_min, x_max, mid=0.75, \n",
    "                    beta1=50.0, beta2=100.0, height=1, \n",
    "                    initial_divisions=11, resolution_factor=1.5):\n",
    "        # determine x0 adaptively values using second derivitive\n",
    "        # could be replaced with less snazzy:\n",
    "        #   x0 = NP.arange(0, 0.5, .001)\n",
    "        x0 = np.array(())\n",
    "        tmpx = np.linspace(0, 0.5, initial_divisions)\n",
    "        tmp = beta1**2 * (np.exp(beta1*tmpx)) * (1-np.exp(beta1*tmpx)) / np.power((1+np.exp(beta1*tmpx)),3)\n",
    "        tmp += beta2**2 * (np.exp(beta2*(tmpx-0.5))) * (1-np.exp(beta2*(tmpx-0.5))) / np.power((1+np.exp(beta2*(tmpx-0.5))),3)\n",
    "        for i in range(0, len(tmpx)-1):\n",
    "            t = int(np.ceil(resolution_factor*max(np.abs(tmp[i:i+2]))/float(initial_divisions)))\n",
    "            x0 = np.append(x0, np.linspace(tmpx[i],tmpx[i+1],t))\n",
    "        x0 = np.sort(np.unique(x0)) # sort and remove dups\n",
    "        # half brace using sum of two logistic functions\n",
    "        y0 = mid*2*((1/(1.+np.exp(-1*beta1*x0)))-0.5)\n",
    "        y0 += (1-mid)*2*(1/(1.+np.exp(-1*beta2*(x0-0.5))))\n",
    "        # concat and scale x\n",
    "        x = np.concatenate((x0, 1-x0[::-1])) * float((x_max-x_min)) + x_min\n",
    "        y = np.concatenate((y0, y0[::-1])) * float(height)\n",
    "        return (x,y)\n",
    "\n",
    "    fig  = plt.figure(figsize=(18, 9))\n",
    "    grid_shape = (39,37)\n",
    "\n",
    "    axes_list = ['ax_n1', 'ax_n2', 'ax_predicted_negative', 'ax_predicted_positive', 'ax_actual_negative', 'ax_actual_positive', \n",
    "    'ax_true_negative', 'ax_false_positive',  'ax_false_negative', 'ax_true_positive', 'ax_total_predicted_negative', 'ax_total_predicted_positive',  'ax_total_actual_negative', 'ax_total_actual_positive', 'ax_precision', 'ax_negative_predictive_value',  'ax_accuracy', 'ax_f1', 'ax_specificity', 'ax_sensitivity',  'ax_predicted_class', 'ax_actual_class', 'ax_top_brace', 'ax_left_brace']\n",
    "    typex = ['coordinates', 'spans', 'facecolor', 'spines']\n",
    "    coordinates = [[(6,3),(2,4), 'w', False], [(24,23),(4,5), 'lavender', True], [(6,7),(2,8), 'pink', True], [(6,15),(2,8), 'pink', True], [(8,3),(8,4), 'pink', True], [(16,3),(8,4), 'pink', True], [(8,7),(8,8), 'w', True], [(8,15),(8,8), 'w', True], [(16,7),(8,8), 'w', True], [(16,15),(8,8), 'w', True], [(24,7),(4,8), 'lavender', True], [(24,15),(4,8), 'lavender', True], [(8,23),(8,5), 'lavender', True], [(16,23),(8,5), 'lavender', True], [(30,15),(9,8), 'antiquewhite', True], [(30,7),(9,8), 'antiquewhite', True], [(30,25),(9,6), 'antiquewhite', True], [(30,31),(9,6), 'antiquewhite', True], [(8,29),(8,8), 'antiquewhite', True], [(16,29),(8,8), 'antiquewhite', True], [(0,7),(2,16), 'w', False], [(8,0),(16,1), 'w', False], [(2,7),(3,16), 'w', False], [(8,1),(16,1), 'w', False]   ]\n",
    "    d = {}\n",
    "    for ax, coordinates in zip(axes_list, coordinates):\n",
    "        d[ax] = dict(zip(typex, coordinates))\n",
    "    axes={}    \n",
    "    for ax, v in d.items():\n",
    "        loc = d[ax]['coordinates']\n",
    "        rowspan, colspan = d[ax]['spans']\n",
    "        facecolor = d[ax]['facecolor']\n",
    "        spines = d[ax]['spines']\n",
    "        axes[ax] = plt.subplot2grid(shape=grid_shape, loc=loc, rowspan=rowspan, colspan=colspan, facecolor=facecolor, xticks=[], yticks=[])\n",
    "        for sp in axes[ax].spines.values():\n",
    "            sp.set_visible(spines)\n",
    "\n",
    "    # draw the top brace\n",
    "    x,y = range_brace(0, 1)\n",
    "    axes['ax_top_brace'].set_xlim(0,1)\n",
    "    axes['ax_top_brace'].set_ylim(0,1)\n",
    "    axes['ax_top_brace'].plot(x, y,'-', clip_on=False)\n",
    "\n",
    "    # draw the left brace\n",
    "    x,y = range_brace(0, 1)\n",
    "    axes['ax_left_brace'].set_xlim(0,1)\n",
    "    axes['ax_left_brace'].set_ylim(0,1)    \n",
    "    base = plt.gca().transData\n",
    "    rot = transforms.Affine2D().rotate_deg_around(.5, .5, 90)\n",
    "    axes['ax_left_brace'].plot(x, y,'-', clip_on=False, transform=rot+base)\n",
    "\n",
    "    typexx = ['ax', 'coord', 'text', 'align', 'fontsize', 'weight', 'color', 'path_effectsx', 'rotationx']\n",
    "    text_list = [\n",
    "        ['ax_n2',(.5, .7), 'Total', ('center', 'center'), 20, 'normal', 'black', False, 0], \n",
    "        ['ax_n2',(.5, .3), f'{(tn+tp+fn+fp):,.0f}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_predicted_negative',(.5, .5), 'Negative', ('center', 'center'), 15, 'bold', 'black', False, 0],\n",
    "        ['ax_predicted_positive',(.5, .5), 'Positive', ('center', 'center'), 15, 'bold', 'black', False, 0],\n",
    "        ['ax_actual_negative',(.5, .5), 'Negative', ('center', 'center'), 15, 'bold', 'black', False, 0],\n",
    "        ['ax_actual_positive',(.5, .5), 'Positive', ('center', 'center'), 15, 'bold', 'black', False, 0],\n",
    "        ['ax_true_negative',(.5, .7), 'True Negative (TN)', ('center', 'center'), 18, 'normal', 'green', True, 0],\n",
    "        ['ax_true_negative',(.5, .3), f'{tn:,.0f}', ('center', 'center'), 18, 'normal', 'green', True, 0],\n",
    "        ['ax_false_positive',(.5, .8), 'False Positive (FP))', ('center', 'center'), 18, 'normal', 'red', True, 0],\n",
    "        ['ax_false_positive',(.5, .55), '(Type I Error)', ('center', 'center'), 16, 'normal', 'darkred', False, 0],\n",
    "        ['ax_false_positive',(.5, .3), f'{fp:,.0f}', ('center', 'center'), 20, 'normal', 'red', False, 0],\n",
    "        ['ax_false_negative',(.5, .8), 'False Negative (FN)', ('center', 'center'), 18, 'normal', 'red', True, 0],\n",
    "        ['ax_false_negative',(.5, .55), '(Type II Error)', ('center', 'center'), 16, 'normal', 'darkred', False, 0],\n",
    "        ['ax_false_negative',(.5, .3), f'{fn:,.0f}', ('center', 'center'), 20, 'normal', 'red', False, 0],\n",
    "        ['ax_true_positive',(.5, .7), 'True Positive (TP)', ('center', 'center'), 18, 'normal', 'green', True, 0],\n",
    "        ['ax_true_positive',(.5, .3), f'{tp:,.0f}', ('center', 'center'), 20, 'normal', 'green', False, 0],\n",
    "        ['ax_total_predicted_negative',(.5, .7), 'Total Predicted Negative', ('center', 'center'), 14, 'normal', 'black', False, 0],\n",
    "        ['ax_total_predicted_negative',(.5, .3), f'{(tn+fn):,.0f}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_total_predicted_positive',(.5, .7), 'Total Predicted Positive', ('center', 'center'), 14, 'normal', 'black', False, 0],\n",
    "        ['ax_total_predicted_positive',(.5, .3), f'{(tp+fp):,.0f}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_total_actual_negative',(.5, .7), 'Total\\nActual Negative', ('center', 'center'), 14, 'normal', 'black', False, 0],\n",
    "        ['ax_total_actual_negative',(.5, .3), f'{(tn+fp):,.0f}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_total_actual_positive',(.5, .7), 'Total\\nActual Positive', ('center', 'center'), 14, 'normal', 'black', False, 0],\n",
    "        ['ax_total_actual_positive',(.5, .3), f'{(tp+fn):,.0f}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_precision',(.5, .8), 'Precision\\nPositive Predictive Value', ('center', 'center'), 15, 'normal', 'black', False, 0],\n",
    "        ['ax_precision',(.5, .45), r'$\\frac{TP}{TP+FP}$', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_precision',(.5, .1), f'{tp / (tp+fp):.2%}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_negative_predictive_value',(.5, .8), 'Negative Predictive Value', ('center', 'center'), 15, 'normal', 'black', False, 0],\n",
    "        ['ax_negative_predictive_value',(.5, .45), r'$\\frac{TN}{TN+FN}$', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_negative_predictive_value',(.5, .1), f'{tn / (tn+fn):.2%}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_accuracy',(.5, .8), 'Accuracy', ('center', 'center'), 15, 'normal', 'black', False, 0],\n",
    "        ['ax_accuracy',(.5, .45), r'$\\frac{TP+TN}{TP+TN+FP+FN}$', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_accuracy',(.5, .1), f'{(tn+tp) / (tn+tp+fn+fp):.2%}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_f1',(.5, .8), 'F1 Score', ('center', 'center'), 15, 'normal', 'black', False, 0],\n",
    "        ['ax_f1',(.5, .45), r'$2\\left(\\frac{(Precision)(Recall)}{Precision + Recall}\\right)$', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_f1',(.5, .1), f'{2*(((tp/(tp+fp)) * (tp/(tp+fn))) / ((tp/(tp+fp)) + (tp/(tp+fn)))):.2%}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_specificity',(.5, .8), 'True Negative Rate (TNR)\\nSpecificity', ('center', 'center'), 15, 'normal', 'black', False, 0],\n",
    "        ['ax_specificity',(.5, .425), r'$\\frac{TN}{TN+FP}$', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_specificity',(.5, .1), f'{(tn) / (tn+fp):.2%}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_sensitivity',(.5, .8), 'True Positive Rate (TPR)\\nSensitivity or Recall', ('center', 'center'), 15, 'normal', 'black', False, 0],\n",
    "        ['ax_sensitivity',(.5, .425), r'$\\frac{TP}{TP+FN}$', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_sensitivity',(.5, .1), f'{(tp) / (tp+fn):.2%}', ('center', 'center'), 20, 'normal', 'black', False, 0],\n",
    "        ['ax_predicted_class',(.5, .5), 'Predicted Class', ('center', 'center'), 15, 'bold', 'black', False, 0],\n",
    "        ['ax_actual_class',(.5, .5), 'Actual Class', ('center', 'center'), 15, 'bold', 'black', False, 90]]\n",
    "\n",
    "    d2 = {}\n",
    "    for ax, text_list in zip(range(len(text_list)), text_list):\n",
    "        d2[ax] = dict(zip(typexx, text_list))\n",
    "\n",
    "    for key, value in d2.items():\n",
    "        x, y = value['coord']\n",
    "        txt = value['text']\n",
    "        va, ha = value['align']\n",
    "        fontsize = value['fontsize']\n",
    "        weight = value['weight']\n",
    "        color = value['color']\n",
    "        path_effectsx = value['path_effectsx']\n",
    "        if path_effectsx == True:\n",
    "            path_effects_var = [path_effects.withSimplePatchShadow()]\n",
    "        else:\n",
    "            path_effects_var = False\n",
    "        rotationx = value['rotationx']\n",
    "\n",
    "        axes[d2[key]['ax']].text(x=x, y=y, s=txt, va=va, ha=ha, fontsize=fontsize, weight=weight, color=color, path_effects=path_effects_var, rotation=rotationx)\n",
    "\n",
    "    plt.suptitle('Confusion Matrix Plus', fontsize=30)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    print('')\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "@time_it\n",
    "def show_errors_gt_ff(k=2, filename=None, model=False):\n",
    "    assert Path.cwd().name == 'intermediary reports'\n",
    "\n",
    "    if filename == None:\n",
    "        files = df_mtcnn['path_file'].unique()\n",
    "        if len(files) > k:  # sample w/o replacement if we have enough, otherwise use replacement\n",
    "            files = random.sample(list(files), k)  # sample w/o replacement\n",
    "        else:\n",
    "            files = random.choices(list(files), k)  # sample w/ replacement\n",
    "    else:\n",
    "        files = list(df_gt[df_gt['file_only']==filename]['source_file'].unique())\n",
    "\n",
    "    for file in files:\n",
    "        ret, image, pct_resize = read_image(file, True)\n",
    "        if not ret:\n",
    "            assert 1 == 2\n",
    "\n",
    "        # start by drawing all the gt faces in green\n",
    "        df = df_gt[df_gt['source_file']==file]\n",
    "        for index, row in df.iterrows():\n",
    "            cv2.circle(image, (int(row['gt_x'] * pct_resize), int(row['gt_y'] * pct_resize)), 25,\n",
    "               (102, 255, 0), 3) # green\n",
    "    \n",
    "        df = df_mtcnn[df_mtcnn['path_file']==file]\n",
    "        for index, row in df.iterrows():\n",
    "            # draw orange circle over green circle if confirmed\n",
    "            if row['confirmed_gt']:\n",
    "                cv2.circle(image, (int(row['gt_x'] * pct_resize), int(row['gt_y'] * pct_resize)), 25,\n",
    "                           (0, 155, 255), 3) # orange\n",
    "                \n",
    "                cv2.rectangle(image,\n",
    "                              (int(row['x1'] * pct_resize), int(row['y1'] * pct_resize)),\n",
    "                              (int((row['x1'] + row['w']) * pct_resize), int((row['y1'] + row['h'])* pct_resize)),\n",
    "                              (0, 155, 255), 3) # orange\n",
    "            else:\n",
    "                cv2.rectangle(image,\n",
    "                              (int(row['x1'] * pct_resize), int(row['y1'] * pct_resize)),\n",
    "                              (int((row['x1'] + row['w']) * pct_resize), int((row['y1'] + row['h'])* pct_resize)),\n",
    "                              (102, 255, 0), 3) # orange\n",
    "            if model:\n",
    "                if row['bad_faces_model'] == 0:\n",
    "                    cv2.rectangle(image,\n",
    "                              (int(row['x1'] * pct_resize), int(row['y1'] * pct_resize)),\n",
    "                              (int((row['x1'] + row['w']) * pct_resize), int((row['y1'] + row['h'])* pct_resize)),\n",
    "                              (0, 0, 255), 3) # red\n",
    "                    \n",
    "\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        plt.title(file.name + '\\n' + str(image.shape))\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "face alignment..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms to try\n",
    "classification_algos_name = [\n",
    "    \"KNeighborsClassifier\",\n",
    "    \"GaussianNB\",\n",
    "    \"DecisionTreeClassifier\",\n",
    "    \"ExtraTreeClassifier\",\n",
    "    \"RandomForestClassifier\",\n",
    "    \"AdaBoostClassifier\",\n",
    "    \"GradientBoostingClassifier\",\n",
    "    \"XGBClassifier\",\n",
    "    \"LGBMClassifier\",\n",
    "]\n",
    "\n",
    "classification_algos = [\n",
    "    KNeighborsClassifier(20),\n",
    "    GaussianNB(),\n",
    "    DecisionTreeClassifier(),\n",
    "    ExtraTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    XGBClassifier(),\n",
    "    LGBMClassifier(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common variables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common variables used throughout the notebook\n",
    "random.seed(14)\n",
    "\n",
    "DATA_DIR = Path('../../data/')\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth=6)\n",
    "\n",
    "source_path = Path('../../data/01_source_photos/')  # source images\n",
    "\n",
    "start_all = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables from previous notebooks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f_name for d_name in Path(source_path).glob(\"*\") for f_name in d_name.glob('mtcnn_faces/mtcnn_pickles/*') if d_name.is_dir() if f_name.is_file() if f_name.suffix=='.pkl']\n",
    "# file_names = [Path(f).name for f in path_file]\n",
    "# dir_names = [Path(f) for f in path_file]\n",
    "# face_file = [Path(Path(f).parent.parent / f.name).with_suffix('.jpg') for f in path_file]\n",
    "# df_s = pd.DataFrame(zip(file_names, dir_names, path_file, face_file), columns=['org_file','pickle_path','pickle_file', 'face_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "filename = s.MODELS_DIR_jn / 'recognizer.sav'\n",
    "recognizer = pickle.loads(open(filename, \"rb\").read())\n",
    "filename = s.MODELS_DIR_jn / 'le.sav'\n",
    "le = pickle.loads(open(filename, \"rb\").read())\n",
    "# filename = s.MODELS_DIR_jn / 'recognizer_scaler.pkl'\n",
    "# scaler = pickle.loads(open(filename, \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-365e66a1fb51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mvec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vec'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "# embedder = cv2.dnn.readNetFromTorch('../../data/10_other/models/openface_nn4.small2.v1.t7')\n",
    "\n",
    "face_list = []\n",
    "name_list = []\n",
    "# files = df_mtcnn['face_file']\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    x = pickle.loads(open(file, \"rb\").read())\n",
    "    vec=x['vec']\n",
    "    vec = vec.reshape(1, -1)\n",
    "\n",
    "    preds = recognizer.predict_proba(vec)[0]\n",
    "\n",
    "\n",
    "    j = np.argmax(preds)\n",
    "    proba = preds[j]\n",
    "    name = le.classes_[j]\n",
    "    print(name)\n",
    "    print(preds)\n",
    "    print('')\n",
    "    \n",
    "\n",
    "    if preds[np.argmax(preds)] > .90:\n",
    "        y = (file.parent.parent / file.name).with_suffix('.jpg')\n",
    "        print(y)\n",
    "        face_list.append(y)\n",
    "        name_list.append(name)\n",
    "\n",
    "# print(len(face_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, face in enumerate(face_list):\n",
    "    if name_list[i] == '11_Elijah Widdows':\n",
    "#         print(face)\n",
    "        r = cv2.imread(str(face))\n",
    "        cv2.imshow('x', r)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
